"""
Models Supported:

VLM: [
    "LLaVA-NeXT",
    "HuggingFaceTB/SmolVLM-Instruct",
    "google/paligemma2-3b-pt-224",
    "Qwen/Qwen2-VL-2B-Instruct"
]

"""

VQA_CONFIG = {
    "auto_label_mode": "VLM",
    "model": "ybelkada/blip-vqa-base"
}